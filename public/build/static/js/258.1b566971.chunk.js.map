{"version":3,"file":"static/js/258.1b566971.chunk.js","mappings":"iKAsCO,MAAMA,EAAyBC,WAAAA,GAAA,KAC5BC,QAAU,QAAQ,KAElBC,WAAa,CACnBC,OAAQ,CACN,oCACA,oBACA,2BACA,uBACA,0BACA,yBAEFC,SAAU,CAER,sBACA,yBACA,6BACA,4BACA,2BAEFC,OAAQ,CACN,qBACA,yBACA,oBACA,6BAEF,KAEMC,YAAc,CACpBH,OAAQ,CAAC,oBAAqB,8BAC9BC,SAAU,CACR,sBACA,+BACA,+BACA,gCAEF,CAEF,oBAAMG,GACJC,QAAQC,IAAI,kDAEZ,IAEE,MAAMC,QAAiBC,KAAKC,sBAC5B,IAAIC,EAEAH,GACFF,QAAQC,IAAI,0DACZI,EAAkBH,EAASI,UAE3BN,QAAQC,IAAI,+DACZI,QAAwBF,KAAKI,8BAIzBJ,KAAKK,eAAeH,GAE1B,MAAMI,QAAsBN,KAAKO,qBAAqBL,GAOtD,OALAL,QAAQC,IAAI,oCAADU,OAA2BF,EAAcH,QAAQM,OAAM,YAClEZ,QAAQC,IAAI,mBAADU,OAAUF,EAAcI,MAAMC,YAAW,iBAAAH,OAAgBF,EAAcI,MAAME,YAAW,WACnGf,QAAQC,IAAI,mBAADU,OAAUF,EAAcI,MAAMG,cAAa,4BAAAL,OAA2BF,EAAcI,MAAMI,cAAa,WAClHjB,QAAQC,IAAI,aAADU,OAASF,EAAcI,MAAMK,YAAW,0BAE5CT,CACT,CAAE,MAAOU,GAEP,MADAnB,QAAQmB,MAAM,iCAA6BA,GACrCA,CACR,CACF,CAEA,yBAAMf,GACJ,IACE,MAAMgB,QAAiBC,MAAM,+BAC7B,GAAID,EAASE,GAAI,CACf,MAAMpB,QAAiBkB,EAASG,OAiBhC,OAfIrB,GAAYA,EAASI,UACvBJ,EAASI,QAAUJ,EAASI,QAAQkB,IAAKC,IAClCA,EAAOC,OAEU,WAAhBD,EAAOE,KACTF,EAAOC,KAAI,gBAAAf,OAAmBc,EAAOG,UACZ,aAAhBH,EAAOE,KAChBF,EAAOC,KAAI,2BAAAf,OAA8Bc,EAAOG,UACvB,WAAhBH,EAAOE,OAChBF,EAAOC,KAAI,wBAAAf,OAA2Bc,EAAOG,YAG1CH,KAGJvB,CACT,CACF,CAAE,MAAOiB,GACPnB,QAAQC,IAAI,2EACd,CACA,OAAO,IACT,CAEA,0BAAMM,GACJ,MAAMsB,EAA0B,GAG1BC,QAAmB3B,KAAK4B,oBAAoB,UAClDF,EAASG,QAAQF,GAGjB,MAAMb,QAAsBd,KAAK4B,oBAAoB,YACrDF,EAASG,QAAQf,GAGjB,MAAMC,QAAoBf,KAAK4B,oBAAoB,UAMnD,OALAF,EAASG,QAAQd,SAGXf,KAAKK,eAAeqB,GAEnBA,CACT,CAEA,yBAAcE,CAAoBJ,GAChC,MAAMM,EAAuB,GACvBvC,EAAaS,KAAKT,WAAWiC,GAG7BO,EAAqB,aAATP,EAAsB,oBAAsBA,EAE9D,IAAK,MAAMC,KAAYlC,EAAY,CACjC,MAAMyC,EAAG,GAAAxB,OAAMR,KAAKV,QAAO,KAAAkB,OAAIuB,EAAS,KAAAvB,OAAIiB,GAE5C,IACE,MAAMR,QAAiBC,MAAMc,EAAK,CAAEC,OAAQ,SAC5C,GAAIhB,EAASE,GAAI,CACf,MAAMe,EAAWlC,KAAKmC,4BAA4BV,GAElDK,EAAMD,KAAK,CACTN,KAAMS,EACNP,WACAS,WACAV,OACAY,aAAcnB,EAASoB,QAAQC,IAAI,uBAAoBC,EACvDC,KAAMC,SAASxB,EAASoB,QAAQC,IAAI,mBAAqB,MAE7D,CACF,CAAE,MAAOtB,GACP,CAEJ,CAEA,OAAOc,CACT,CAEA,oBAAczB,CAAeyB,GAE3B,IAAK,MAAMY,KAAY1C,KAAKL,YAAYH,OACtC,IACE,MAAMyB,QAAiBC,MAAMwB,EAAU,CAAET,OAAQ,SACjD,GAAIhB,EAASE,GAAI,CACf,MAAMM,EAAWiB,EAASC,MAAM,KAAKC,OAAS,UAC9Cd,EAAMD,KAAK,CACTN,KAAMmB,EACNjB,WACAS,SAAU,SACVV,KAAM,SACNY,aAAcnB,EAASoB,QAAQC,IAAI,uBAAoBC,EACvDC,KAAMC,SAASxB,EAASoB,QAAQC,IAAI,mBAAqB,MAE7D,CACF,CAAE,MAAOtB,GACP,CAKJ,IAAK,MAAM0B,KAAY1C,KAAKL,YAAYF,SACtC,IACE,MAAMwB,QAAiBC,MAAMwB,EAAU,CAAET,OAAQ,SACjD,GAAIhB,EAASE,GAAI,CACf,MAAMM,EAAWiB,EAASC,MAAM,KAAKC,OAAS,UAC9Cd,EAAMD,KAAK,CACTN,KAAMmB,EACNjB,WACAS,SAAU,SACVV,KAAM,WACNY,aAAcnB,EAASoB,QAAQC,IAAI,uBAAoBC,EACvDC,KAAMC,SAASxB,EAASoB,QAAQC,IAAI,mBAAqB,MAE7D,CACF,CAAE,MAAOtB,GACP,CAGN,CAEQmB,2BAAAA,CAA4BV,GAElC,MACMoB,EADWpB,EAASqB,QAAQ,QAAS,IACpBH,MAAM,KAE7B,OAAIE,EAAMpC,OAAS,EAEVoC,EAAME,MAAM,GAAI,GAAGC,KAAK,KAG1B,SACT,CAEA,0BAAczC,CAAqBuB,GACjC,MAAMmB,EAAmB,GACnBC,EAAqB,GACrBC,EAAa,IAAIC,IACjBC,EAAgB,IAAID,IAE1B,IAAIxC,EAAc,EACdE,EAAgB,EAChBC,EAAc,EAElB,IAAK,MAAMuC,KAAQxB,EACjB,IACEjC,QAAQC,IAAI,wBAADU,OAAe8C,EAAK7B,SAAQ,MAAAjB,OAAK8C,EAAKpB,SAAQ,MAEzD,MAAMqB,QAAgBvD,KAAKwD,gBAAgBF,EAAK/B,MAEhD,GAAkB,WAAd+B,EAAK9B,KAAmB,CAC1B,MAAMhC,EAASQ,KAAKyD,yBAAyBF,EAASD,GACtDtD,KAAK0D,oBAAoBlE,EAAQ2D,EAAYF,GAC7CrC,GACF,MAAO,GAAkB,aAAd0C,EAAK9B,KAAqB,CACnC,MAAM/B,EAAWO,KAAK2D,2BAA2BJ,EAASD,GAC1DtD,KAAK0D,oBAAoBjE,EAAU4D,EAAeH,GAClDpC,GACF,MAAO,GAAkB,WAAdwC,EAAK9B,KAAmB,CACjC,MAAMoC,EAAgB5D,KAAK6D,qBAAqBN,EAASD,GACrDM,EAAcpE,QAChBQ,KAAK0D,oBAAoBE,EAAcpE,OAAQ2D,EAAYF,GAEzDW,EAAcnE,UAChBO,KAAK0D,oBAAoBE,EAAcnE,SAAU4D,EAAeH,GAElEnC,GACF,CACF,CAAE,MAAOC,GACPnB,QAAQiE,KAAK,+BAADtD,OAAsB8C,EAAK7B,SAAQ,KAAKT,EACtD,CAGF,MAAO,CACLxB,OAAQyD,EACRxD,SAAUyD,EACV/C,QAAS2B,EACTpB,MAAO,CACLqD,WAAYjC,EAAMrB,OAClBG,cACAE,gBACAC,cACAJ,YAAasC,EAAUxC,OACvBI,cAAeqC,EAAYzC,QAGjC,CAEA,qBAAc+C,CAAgBxB,GAC5B,IACE,MAAMf,QAAiBC,MAAMc,GAC7B,IAAKf,EAASE,GACZ,MAAM,IAAI6C,MAAM,QAADxD,OAASS,EAASgD,OAAM,MAAAzD,OAAKS,EAASiD,aAEvD,aAAajD,EAASG,MACxB,CAAE,MAAOJ,GACP,MAAM,IAAIgD,MAAM,kBAADxD,OAAmBwB,EAAG,MAAAxB,OAAKQ,GAC5C,CACF,CAEQyC,wBAAAA,CAAyBF,EAAcD,GAE7C,OAAIa,MAAMC,QAAQb,GACTA,EAGLA,EAAQ/D,QAAU2E,MAAMC,QAAQb,EAAQ/D,QACnC+D,EAAQ/D,OAGb+D,EAAQc,MAAQF,MAAMC,QAAQb,EAAQc,MACjCd,EAAQc,MAGjBxE,QAAQiE,KAAK,yCAADtD,OAAgC8C,EAAK7B,WAC1C,GACT,CAEQkC,0BAAAA,CAA2BJ,EAAcD,GAE/C,OAAIa,MAAMC,QAAQb,GACTA,EAGLA,EAAQ9D,UAAY0E,MAAMC,QAAQb,EAAQ9D,UACrC8D,EAAQ9D,SAGb8D,EAAQe,UAAYH,MAAMC,QAAQb,EAAQe,UACrCf,EAAQe,SAGbf,EAAQgB,SAAWJ,MAAMC,QAAQb,EAAQgB,SACpChB,EAAQgB,QAGbhB,EAAQc,MAAQF,MAAMC,QAAQb,EAAQc,MACjCd,EAAQc,MAGjBxE,QAAQiE,KAAK,2CAADtD,OAAkC8C,EAAK7B,WAC5C,GACT,CAEQoC,oBAAAA,CAAqBN,EAAcD,GACzC,MAAMkB,EAA+C,CAAC,EAuBtD,OApBIjB,EAAQ/D,QAAU2E,MAAMC,QAAQb,EAAQ/D,UAC1CgF,EAAOhF,OAAS+D,EAAQ/D,QAGtB+D,EAAQ9D,UAAY0E,MAAMC,QAAQb,EAAQ9D,YAC5C+E,EAAO/E,SAAW8D,EAAQ9D,UAIxB0E,MAAMC,QAAQb,KACZD,EAAK7B,SAASgD,SAAS,SACzBD,EAAOhF,OAAS+D,EACPD,EAAK7B,SAASgD,SAAS,YAChCD,EAAO/E,SAAW8D,EAGlBiB,EAAOhF,OAAS+D,GAIbiB,CACT,CAEQd,mBAAAA,CAAoBgB,EAAcC,EAAyBC,GACjE,IAAK,MAAMC,KAAQH,EACjB,GAAIG,GAAQA,EAAKC,GACf,GAAKH,EAAMI,IAAIF,EAAKC,IAGb,CAEL,MAAME,EAAWL,EAAMrC,IAAIuC,EAAKC,IAC1BG,EAASjF,KAAKkF,WAAWF,EAAUH,GACzCF,EAAMQ,IAAIN,EAAKC,GAAIG,GAGnB,MAAMG,EAAQR,EAAYS,UAAUC,GAAKA,EAAER,KAAOD,EAAKC,KACxC,IAAXM,IACFR,EAAYQ,GAASH,EAEzB,MAbEN,EAAMQ,IAAIN,EAAKC,GAAID,GACnBD,EAAY/C,KAAKgD,EAezB,CAEQK,UAAAA,CAAWF,EAAeO,GAGhC,MAAMN,GAAMO,EAAAA,EAAAA,GAAA,GAAQR,GAEpB,IAAK,MAAOS,EAAKC,KAAUC,OAAOC,QAAQL,GACxC,GAAIpB,MAAMC,QAAQsB,IAAUvB,MAAMC,QAAQY,EAASS,IAAO,CAExD,MAAMI,EAAW,IAAIb,EAASS,MAASC,GACvCT,EAAOQ,GAAOI,EAASC,OAAO,CAACjB,EAAMO,IAAUS,EAASE,QAAQlB,KAAUO,EAC5E,MAEEH,EAAOQ,GAAOC,EAIlB,OAAOT,CACT,CAGAe,aAAAA,CAAc1F,GACZ,MAAM2F,EAAa3F,EAAcH,QAAQkB,IAAIiC,GAAQA,EAAKpB,UAC1D,OAAO+D,EAAWH,OAAO,CAAC5D,EAAUkD,IAAUa,EAAWF,QAAQ7D,KAAckD,EACjF,CAGAc,kBAAAA,CAAmB5F,EAA8B4B,GAC/C,OAAO5B,EAAcH,QAAQ2F,OAAOxC,GAAQA,EAAKpB,WAAaA,EAChE,CAGAiE,eAAAA,CAAgB7F,GACd,MAAM,MAAEI,EAAK,QAAEP,GAAYG,EAE3B,IAAI8F,EAAM,0CACVA,GAAM,mBAAA5F,OAAuBE,EAAMqD,WAAU,MAC7CqC,GAAM,cAAA5F,OAAkBE,EAAMC,YAAW,WAAAH,OAAUE,EAAME,YAAW,aACpEwF,GAAM,gBAAA5F,OAAoBE,EAAMG,cAAa,WAAAL,OAAUE,EAAMI,cAAa,aAC1EsF,GAAM,cAAA5F,OAAkBE,EAAMK,YAAW,cAEzCqF,GAAM,+BACN,MAAMC,EAAmBrG,KAAKsG,gBAAgBnG,GAQ9C,OAPAwF,OAAOC,QAAQS,GAAkBE,QAAQC,IAAwB,IAAtBtE,EAAUJ,GAAM0E,EACzDJ,GAAM,MAAA5F,OAAU0B,EAAQ,OACxBJ,EAAMyE,QAASjD,IACb8C,GAAM,QAAA5F,OAAY8C,EAAK7B,SAAQ,MAAAjB,OAAK8C,EAAK9B,KAAI,WAI1C4E,CACT,CAEQE,eAAAA,CAAgBxE,GACtB,MAAM2E,EAA6C,CAAC,EASpD,OAPA3E,EAAMyE,QAAQjD,IACPmD,EAAYnD,EAAKpB,YACpBuE,EAAYnD,EAAKpB,UAAY,IAE/BuE,EAAYnD,EAAKpB,UAAUL,KAAKyB,KAG3BmD,CACT,E","sources":["services/content/BrowserAutoContentLoader.ts"],"sourcesContent":["/**\n * Browser-Compatible Auto Content Loader\n * \n * Loads JSON files from public directory using fetch API.\n * Uses a content manifest to discover available files since browsers\n * cannot directly list directory contents.\n */\n\nexport interface ContentFile {\n  path: string;\n  filename: string;\n  category: string;\n  type: 'habits' | 'research' | 'custom';\n  lastModified?: string;\n  size?: number;\n}\n\nexport interface LoadedContent {\n  habits: any[];\n  research: any[];\n  sources: ContentFile[];\n  stats: {\n    totalFiles: number;\n    habitsFiles: number;\n    researchFiles: number;\n    customFiles: number;\n    totalHabits: number;\n    totalResearch: number;\n  };\n}\n\nexport interface ContentManifest {\n  sources: ContentFile[];\n  stats: any;\n  categories: any;\n  generatedAt: string;\n}\n\nexport class BrowserAutoContentLoader {\n  private baseUrl = '/data';\n  \n  private knownFiles = {\n    habits: [\n      'fixed-all-content-2025-08-12.json', // Merged content file\n      'sleep-habits.json',\n      'productivity-habits.json',\n      'exercise-habits.json',\n      'mindfulness-habits.json',\n      'nutrition-habits.json'\n    ],\n    research: [\n      // Files in research-articles directory\n      'sleep-research.json',\n      'exercise-research.json', \n      'productivity-research.json',\n      'mindfulness-research.json',\n      'nutrition-research.json'\n    ],\n    custom: [\n      'custom-habits.json',\n      'personal-research.json',\n      'my-additions.json',\n      'experimental-habits.json'\n    ]\n  };\n\n  private legacyFiles = {\n    habits: ['/data/habits.json', '/data/enhanced_habits.json'],\n    research: [\n      '/data/research.json', \n      '/data/research_articles.json', \n      '/data/enhanced_research.json',\n      '/data/research/research.json' // Also check old research directory\n    ]\n  };\n\n  async loadAllContent(): Promise<LoadedContent> {\n    console.log('üîç Auto-discovering content files...');\n    \n    try {\n      // First try to load from manifest if available\n      const manifest = await this.loadContentManifest();\n      let discoveredFiles: ContentFile[];\n      \n      if (manifest) {\n        console.log('üìã Using content manifest for file discovery');\n        discoveredFiles = manifest.sources;\n      } else {\n        console.log('üîç Discovering files manually (no manifest found)');\n        discoveredFiles = await this.discoverContentFiles();\n      }\n      \n      // Always add legacy files as they might not be in the manifest\n      await this.addLegacyFiles(discoveredFiles);\n      \n      const loadedContent = await this.loadContentFromFiles(discoveredFiles);\n      \n      console.log(`üìä Content loaded from ${loadedContent.sources.length} files:`);\n      console.log(`   üìù ${loadedContent.stats.totalHabits} habits from ${loadedContent.stats.habitsFiles} files`);\n      console.log(`   üìö ${loadedContent.stats.totalResearch} research articles from ${loadedContent.stats.researchFiles} files`);\n      console.log(`   ‚≠ê ${loadedContent.stats.customFiles} custom content files`);\n\n      return loadedContent;\n    } catch (error) {\n      console.error('‚ùå Failed to load content:', error);\n      throw error;\n    }\n  }\n\n  async loadContentManifest(): Promise<ContentManifest | null> {\n    try {\n      const response = await fetch('/data/content-manifest.json');\n      if (response.ok) {\n        const manifest = await response.json();\n        // Add paths to the manifest sources\n        if (manifest && manifest.sources) {\n          manifest.sources = manifest.sources.map((source: any) => {\n            if (!source.path) {\n              // Construct the path based on type\n              if (source.type === 'habits') {\n                source.path = `/data/habits/${source.filename}`;\n              } else if (source.type === 'research') {\n                source.path = `/data/research-articles/${source.filename}`;\n              } else if (source.type === 'custom') {\n                source.path = `/data/content-custom/${source.filename}`;\n              }\n            }\n            return source;\n          });\n        }\n        return manifest;\n      }\n    } catch (error) {\n      console.log('üìã No content manifest found, falling back to manual discovery');\n    }\n    return null;\n  }\n\n  async discoverContentFiles(): Promise<ContentFile[]> {\n    const allFiles: ContentFile[] = [];\n    \n    // Discover habit files\n    const habitFiles = await this.discoverFilesOfType('habits');\n    allFiles.push(...habitFiles);\n\n    // Discover research files  \n    const researchFiles = await this.discoverFilesOfType('research');\n    allFiles.push(...researchFiles);\n\n    // Discover custom content files\n    const customFiles = await this.discoverFilesOfType('custom');\n    allFiles.push(...customFiles);\n\n    // Add legacy files\n    await this.addLegacyFiles(allFiles);\n\n    return allFiles;\n  }\n\n  private async discoverFilesOfType(type: 'habits' | 'research' | 'custom'): Promise<ContentFile[]> {\n    const files: ContentFile[] = [];\n    const knownFiles = this.knownFiles[type];\n    \n    // Use correct directory path for research articles\n    const directory = type === 'research' ? 'research-articles' : type;\n    \n    for (const filename of knownFiles) {\n      const url = `${this.baseUrl}/${directory}/${filename}`;\n      \n      try {\n        const response = await fetch(url, { method: 'HEAD' });\n        if (response.ok) {\n          const category = this.extractCategoryFromFilename(filename);\n          \n          files.push({\n            path: url,\n            filename,\n            category,\n            type,\n            lastModified: response.headers.get('Last-Modified') || undefined,\n            size: parseInt(response.headers.get('Content-Length') || '0')\n          });\n        }\n      } catch (error) {\n        // File doesn't exist, skip it\n      }\n    }\n\n    return files;\n  }\n\n  private async addLegacyFiles(files: ContentFile[]): Promise<void> {\n    // Add legacy habit files\n    for (const filePath of this.legacyFiles.habits) {\n      try {\n        const response = await fetch(filePath, { method: 'HEAD' });\n        if (response.ok) {\n          const filename = filePath.split('/').pop() || 'unknown';\n          files.push({\n            path: filePath,\n            filename,\n            category: 'legacy',\n            type: 'habits',\n            lastModified: response.headers.get('Last-Modified') || undefined,\n            size: parseInt(response.headers.get('Content-Length') || '0')\n          });\n        }\n      } catch (error) {\n        // File doesn't exist, skip\n      }\n    }\n\n    // Add legacy research files\n    for (const filePath of this.legacyFiles.research) {\n      try {\n        const response = await fetch(filePath, { method: 'HEAD' });\n        if (response.ok) {\n          const filename = filePath.split('/').pop() || 'unknown';\n          files.push({\n            path: filePath,\n            filename,\n            category: 'legacy',\n            type: 'research',\n            lastModified: response.headers.get('Last-Modified') || undefined,\n            size: parseInt(response.headers.get('Content-Length') || '0')\n          });\n        }\n      } catch (error) {\n        // File doesn't exist, skip\n      }\n    }\n  }\n\n  private extractCategoryFromFilename(filename: string): string {\n    // Extract category from filename patterns like 'sleep-habits.json' -> 'sleep'\n    const basename = filename.replace('.json', '');\n    const parts = basename.split('-');\n    \n    if (parts.length > 1) {\n      // Return everything except the last part (habits/research)\n      return parts.slice(0, -1).join('-');\n    }\n    \n    return 'general';\n  }\n\n  private async loadContentFromFiles(files: ContentFile[]): Promise<LoadedContent> {\n    const allHabits: any[] = [];\n    const allResearch: any[] = [];\n    const habitIdMap = new Map();\n    const researchIdMap = new Map();\n    \n    let habitsFiles = 0;\n    let researchFiles = 0;\n    let customFiles = 0;\n\n    for (const file of files) {\n      try {\n        console.log(`üìÇ Loading ${file.filename} (${file.category})`);\n        \n        const content = await this.loadFileContent(file.path);\n        \n        if (file.type === 'habits') {\n          const habits = this.extractHabitsFromContent(content, file);\n          this.deduplicateAndMerge(habits, habitIdMap, allHabits);\n          habitsFiles++;\n        } else if (file.type === 'research') {\n          const research = this.extractResearchFromContent(content, file);\n          this.deduplicateAndMerge(research, researchIdMap, allResearch);\n          researchFiles++;\n        } else if (file.type === 'custom') {\n          const customContent = this.extractCustomContent(content, file);\n          if (customContent.habits) {\n            this.deduplicateAndMerge(customContent.habits, habitIdMap, allHabits);\n          }\n          if (customContent.research) {\n            this.deduplicateAndMerge(customContent.research, researchIdMap, allResearch);\n          }\n          customFiles++;\n        }\n      } catch (error) {\n        console.warn(`‚ö†Ô∏è Failed to load ${file.filename}:`, error);\n      }\n    }\n\n    return {\n      habits: allHabits,\n      research: allResearch,\n      sources: files,\n      stats: {\n        totalFiles: files.length,\n        habitsFiles,\n        researchFiles,\n        customFiles,\n        totalHabits: allHabits.length,\n        totalResearch: allResearch.length\n      }\n    };\n  }\n\n  private async loadFileContent(url: string): Promise<any> {\n    try {\n      const response = await fetch(url);\n      if (!response.ok) {\n        throw new Error(`HTTP ${response.status}: ${response.statusText}`);\n      }\n      return await response.json();\n    } catch (error) {\n      throw new Error(`Failed to load ${url}: ${error}`);\n    }\n  }\n\n  private extractHabitsFromContent(content: any, file: ContentFile): any[] {\n    // Handle different JSON structures\n    if (Array.isArray(content)) {\n      return content;\n    }\n    \n    if (content.habits && Array.isArray(content.habits)) {\n      return content.habits;\n    }\n    \n    if (content.data && Array.isArray(content.data)) {\n      return content.data;\n    }\n\n    console.warn(`‚ö†Ô∏è Unknown habits format in ${file.filename}`);\n    return [];\n  }\n\n  private extractResearchFromContent(content: any, file: ContentFile): any[] {\n    // Handle different JSON structures\n    if (Array.isArray(content)) {\n      return content;\n    }\n    \n    if (content.research && Array.isArray(content.research)) {\n      return content.research;\n    }\n    \n    if (content.articles && Array.isArray(content.articles)) {\n      return content.articles;\n    }\n    \n    if (content.studies && Array.isArray(content.studies)) {\n      return content.studies;\n    }\n    \n    if (content.data && Array.isArray(content.data)) {\n      return content.data;\n    }\n\n    console.warn(`‚ö†Ô∏è Unknown research format in ${file.filename}`);\n    return [];\n  }\n\n  private extractCustomContent(content: any, file: ContentFile): { habits?: any[], research?: any[] } {\n    const result: { habits?: any[], research?: any[] } = {};\n    \n    // Custom files can contain both habits and research\n    if (content.habits && Array.isArray(content.habits)) {\n      result.habits = content.habits;\n    }\n    \n    if (content.research && Array.isArray(content.research)) {\n      result.research = content.research;\n    }\n    \n    // If it's just an array, try to determine type from filename\n    if (Array.isArray(content)) {\n      if (file.filename.includes('habit')) {\n        result.habits = content;\n      } else if (file.filename.includes('research')) {\n        result.research = content;\n      } else {\n        // Default to habits for unknown arrays in custom files\n        result.habits = content;\n      }\n    }\n    \n    return result;\n  }\n\n  private deduplicateAndMerge(items: any[], idMap: Map<string, any>, targetArray: any[]): void {\n    for (const item of items) {\n      if (item && item.id) {\n        if (!idMap.has(item.id)) {\n          idMap.set(item.id, item);\n          targetArray.push(item);\n        } else {\n          // Item already exists, potentially merge or update\n          const existing = idMap.get(item.id);\n          const merged = this.mergeItems(existing, item);\n          idMap.set(item.id, merged);\n          \n          // Update in target array\n          const index = targetArray.findIndex(i => i.id === item.id);\n          if (index !== -1) {\n            targetArray[index] = merged;\n          }\n        }\n      }\n    }\n  }\n\n  private mergeItems(existing: any, newItem: any): any {\n    // Merge strategy: new item properties override existing ones\n    // But preserve arrays by merging unique values\n    const merged = { ...existing };\n    \n    for (const [key, value] of Object.entries(newItem)) {\n      if (Array.isArray(value) && Array.isArray(existing[key])) {\n        // Merge arrays, keeping unique values\n        const combined = [...existing[key], ...value];\n        merged[key] = combined.filter((item, index) => combined.indexOf(item) === index);\n      } else {\n        // Override with new value\n        merged[key] = value;\n      }\n    }\n    \n    return merged;\n  }\n\n  // Method to get available categories\n  getCategories(loadedContent: LoadedContent): string[] {\n    const categories = loadedContent.sources.map(file => file.category);\n    return categories.filter((category, index) => categories.indexOf(category) === index);\n  }\n\n  // Method to get files by category\n  getFilesByCategory(loadedContent: LoadedContent, category: string): ContentFile[] {\n    return loadedContent.sources.filter(file => file.category === category);\n  }\n\n  // Method to get loading statistics\n  getLoadingStats(loadedContent: LoadedContent): string {\n    const { stats, sources } = loadedContent;\n    \n    let report = `üìä Content Loading Summary:\\n`;\n    report += `   Total Files: ${stats.totalFiles}\\n`;\n    report += `   Habits: ${stats.totalHabits} (from ${stats.habitsFiles} files)\\n`;\n    report += `   Research: ${stats.totalResearch} (from ${stats.researchFiles} files)\\n`;\n    report += `   Custom: ${stats.customFiles} files\\n\\n`;\n    \n    report += `üìÅ Source Files:\\n`;\n    const categorizedFiles = this.categorizeFiles(sources);\n    Object.entries(categorizedFiles).forEach(([category, files]) => {\n      report += `   ${category}:\\n`;\n      files.forEach((file: ContentFile) => {\n        report += `     ${file.filename} (${file.type})\\n`;\n      });\n    });\n    \n    return report;\n  }\n\n  private categorizeFiles(files: ContentFile[]): Record<string, ContentFile[]> {\n    const categorized: Record<string, ContentFile[]> = {};\n    \n    files.forEach(file => {\n      if (!categorized[file.category]) {\n        categorized[file.category] = [];\n      }\n      categorized[file.category].push(file);\n    });\n    \n    return categorized;\n  }\n}"],"names":["BrowserAutoContentLoader","constructor","baseUrl","knownFiles","habits","research","custom","legacyFiles","loadAllContent","console","log","manifest","this","loadContentManifest","discoveredFiles","sources","discoverContentFiles","addLegacyFiles","loadedContent","loadContentFromFiles","concat","length","stats","totalHabits","habitsFiles","totalResearch","researchFiles","customFiles","error","response","fetch","ok","json","map","source","path","type","filename","allFiles","habitFiles","discoverFilesOfType","push","files","directory","url","method","category","extractCategoryFromFilename","lastModified","headers","get","undefined","size","parseInt","filePath","split","pop","parts","replace","slice","join","allHabits","allResearch","habitIdMap","Map","researchIdMap","file","content","loadFileContent","extractHabitsFromContent","deduplicateAndMerge","extractResearchFromContent","customContent","extractCustomContent","warn","totalFiles","Error","status","statusText","Array","isArray","data","articles","studies","result","includes","items","idMap","targetArray","item","id","has","existing","merged","mergeItems","set","index","findIndex","i","newItem","_objectSpread","key","value","Object","entries","combined","filter","indexOf","getCategories","categories","getFilesByCategory","getLoadingStats","report","categorizedFiles","categorizeFiles","forEach","_ref","categorized"],"sourceRoot":""}